# Default values for osiris chart.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

# Service account settings - useful if your pods need specific permissions
serviceAccount:
  create: true
  annotations: {}
  name: ""

# Orchestrator specific values
orchestrator:
  name: orchestrator
  replicaCount: 1 # Default replica count for orchestrator
  image:
    repository: your-repo/orchestrator # Placeholder
    pullPolicy: IfNotPresent
    tag: "latest"
  service:
    type: ClusterIP
    port: 80
  resources: {}
  #   limits:
  #     cpu: 100m
  #     memory: 128Mi
  #   requests:
  #     cpu: 100m
  #     memory: 128Mi
  podSecurityContext: {} # Default empty map
  #  fsGroup: 2000
  securityContext: {} # Default empty map
  #  capabilities:
  #    drop:
  #    - ALL
  #  readOnlyRootFilesystem: true
  #  runAsNonRoot: true
  #  runAsUser: 1000
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
  nodeSelector: {}
  tolerations: []
  affinity: {}
  config: {} # Placeholder for application-specific configurations, e.g., key: value pairs

# LLM-Sidecar specific values
llmSidecar:
  name: llm-sidecar
  replicaCount: 1 # Default replica count for llmSidecar
  image:
    repository: your-repo/llm-sidecar # Placeholder
    pullPolicy: IfNotPresent
    tag: "latest"
  service:
    type: ClusterIP
    port: 8000 # Matches docker/compose.yaml

  # GPU node selector. Adapt to your cluster's GPU node labels.
  # Example: if nodes are labeled 'accelerator=nvidia-tesla-v100' or 'gpu=true'
  nodeSelector: {}
  #   gpu: "true"
  #   accelerator: "nvidia-tesla-v100"

  resources: {}
  # Example for GPU:
  #   limits:
  #     cpu: "2"
  #     memory: "8Gi"
  #     nvidia.com/gpu: 1 # Requesting 1 GPU
  #   requests:
  #     cpu: "1"
  #     memory: "4Gi"
  #     nvidia.com/gpu: 1 # Requesting 1 GPU
  podSecurityContext: {} # Default empty map
  securityContext: {} # Default empty map
  autoscaling:
    enabled: false
  tolerations: [] # For GPU nodes if they have taints (e.g., nvidia.com/gpu=present:NoSchedule)
  affinity: {}
  config: {} # Placeholder for application-specific configurations

# Redis specific values
redis:
  name: redis
  image:
    repository: redis
    pullPolicy: IfNotPresent
    tag: "alpine"
  service:
    type: ClusterIP
    port: 6379
  resources: {}
  #   limits:
  #     cpu: 500m
  #     memory: 512Mi
  #   requests:
  #     cpu: 200m
  #     memory: 256Mi
  # For production, consider a StatefulSet and proper persistence configuration.
  persistence:
    enabled: false
    # storageClassName: "standard" # Example: "gp2" on AWS, "standard" on GKE
    # size: 1Gi
    # accessModes:
    #   - ReadWriteOnce
  # securityContext for Redis pod (example, adjust as per redis image requirements)
  podSecurityContext:
    fsGroup: 1001
    runAsUser: 1001
  # securityContext for Redis container
  securityContext:
    runAsNonRoot: true
    runAsUser: 1001


# Placeholder for other global settings
global: {}
